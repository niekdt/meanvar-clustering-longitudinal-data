---
title: "Analysis of case study MV-GMM results"
author: "Niek Den Teuling"
date: "`r format(Sys.Date())`"
params:
  Rhat: 1.1
  ConvProp: .8
  Experiment: logcovid0-final
  MaskData: '../data/nytimes/covid-19-data/mask-use/mask-use-by-county.csv'
  PrevalenceData: '../data/cdc/cdc_90519_DS1.csv'
  DensityData: '../data/ykzeng/covid-19/data/census-landarea-all.csv'
  FigDir: '../figs-mv'
output:
  html_notebook:
    toc: true
    toc_float: true
    toc_collapsed: true
  html_document: 
    toc: yes
    highlight: tango
    number_sections: yes
editor_options: 
  chunk_output_type: inline
---

```{r setup}
RHAT_LIM = as.numeric(params$Rhat)
CONVPROP_MIN = as.numeric(params$ConvProp)
MVFIG_DIR = params$FigDir
```

```{r, results='hide'}
suppressPackageStartupMessages({
  library(usmap)
  library(matrixStats)
  library(emmeans)
  library(nnet)
  library(car)
})
```

# Data processing
```{r warning=FALSE, results='hide'}
sim_init()
dtAllModels_raw = getCaseTable(params$Experiment, 
  model == 'gmm-mv_full_diag' & use_sdzs == FALSE & use_sigmas == FALSE)
  
dtAllModels = processCaseTable(dtAllModels_raw) %>%
  .[, Index := 1:.N] %>%
  .[]

# saveRDS(dtAllModels, file.path(RESULTS_DIR, 'mvCaseTable.rds'))
# dtAllModels = readRDS(file.path(RESULTS_DIR, 'mvCaseTable.rds'))
allModels = attr(dtAllModels, 'models')
```

Select models for settings
```{r}
dtModels = dtAllModels[
  data.state == 'all' &
  use_sdzs == FALSE &
  nClusters <= 4
]
rhatCols = grep('^Rhat\\.', names(dtModels), value = TRUE)
```

# Class enumeration
WAIC
```{r}
dtModels[use_sigmas == FALSE & ConvProp > CONVPROP_MIN, .(WAIC=min(WAIC)), by=.(nClusters)][is.finite(WAIC)] %>%
  ggplot(aes(x = nClusters, y = WAIC)) +
  geom_line(size=.5) +
  geom_point(color='white', size=3) +
  geom_point(size=2) +
  scale_x_continuous(breaks = 1:10) +
  scale_y_continuous(breaks = pretty_breaks(5), labels = comma) +
  theme(panel.grid.minor.x = element_blank()) +
  labs(x = 'Number of clusters', y = 'WAIC')
ggsave(filename=file.path(MVFIG_DIR, 'mv-waic.pdf'), width=6, height=5, units='cm')
```

# Model selection
Compare models for a specific method and number of classes.
```{r}
# use_sigmas = FALSE
# group sigma estimates are generally highly accurate. However, the variance in the cluster with many spurious zeros has an assymetric variance, resulting in an overestimation of the true variance. (This happens in the non-parametric estimate too)
# k=4 
# seed=9 (127347.8): lowest WAIC, not fully converged. Result is the same as more converged models though
# seed=7 (127392.6): good. preferred model. low entropy
# seed=3 (127528.1): good. high entropy. Only cv2 did not converge
# seed=7 (127549.9): fully converged. low entropy
# use_sigmas = TRUE: overall considerably lower WAIC
# k=3 
# seed=3 good result, very low WAIC. perfect convergence. sane coefs preferred. entropy=.77
# seed=8 good result, lowest WAIC. conv=.88, entropy=.75
# k=4
# very difficult to estimate, with very few reaching 100% convergence. Overall, no considerably different results from use_sigmas = FALSE. All but one of the converged models has a lower WAIC than equivalent use_sigmas=FALSE
# seed=10 (117966.9): only model with full convergence. very low WAIC=117966.9. crazy estimate for sigma1
# seed=3 (127416.1 and 127521.8): severely overestimates variability in class D (the zero-constant  group)
dtBestModels = dtModels[nClusters == 4 & use_sigmas == FALSE, ]

dtBestModels[ConvProp > .8, .(seed, Index, WAIC, ConvProp, warmup, samples, adapt_delta)] %>%
  .[order(WAIC)]
```

# Preferred model
```{r}
bestIdx = dtBestModels[seed == 7 & samples == 1e3 & warmup == 2e3 & adapt_delta == .7, Index]
bestModel = allModels[[bestIdx]]

data = model.data(bestModel) %>%
  copy() %>%
  .[, Cluster := trajectoryAssignments(bestModel)[latrend:::make.idRowIndices(bestModel, .SD)]] %>%
  .[, fips := FIPS] %>%
  .[]

dtDatetime = data.table(
  Time = unique(data$Time), 
  Date = seq(min(data$LastDate), max(data$LastDate), length.out = uniqueN(data$Time)))

dtTraj = clusterTrajectories(bestModel) %>%
  .[dtDatetime, on = 'Time'] %>%
  setkey(Cluster, Time)

dtSigmaTraj = clusterTrajectories(bestModel, what = 'sigma', transform = exp) %>%
  setkey(Cluster, Time)
dtTraj$Sigma = dtSigmaTraj$LogNormNewConfirmed

clusOrder = dtTraj[, last(LogNormNewConfirmed), keyby=Cluster][, order(-V1)]
# clusOrder = seq_len(nClusters(bestModel))
clusNames = NA
clusNames[clusOrder] = LETTERS[seq_len(nClusters(bestModel))]

# map for converting the original class-specific parameters to the proper index of k
clusMap = match(seq_len(nClusters(bestModel)), clusOrder) %>% 
  set_names(paste('Class', seq_len(nClusters(bestModel))))

clusNameMap = clusNames %>%
  set_names(paste('Class', seq_len(nClusters(bestModel))))

dtTraj[, Class := factor(Cluster, 
  levels = clusterNames(bestModel)[clusOrder], 
  labels = sprintf('%s (%s)', clusNames[clusOrder],
    pct(clusterProportions(bestModel)[clusOrder], 2)))]

data[, Class := factor(Cluster, 
  levels = clusterNames(bestModel)[clusOrder], 
  labels = sprintf('%s (%s)', clusNames[clusOrder],
    pct(clusterProportions(bestModel)[clusOrder], 2)))]

colors = switch(as.character(nClusters(bestModel)),
  `1` = 'black',
  `2` = viridis_pal(begin = .05, end = .85, direction = -1, option = 'viridis')(2),
  `3` = viridis_pal(begin = .05, end = .85, direction = -1, option = 'viridis')(3),
  `4` = viridis_pal(begin = 0, end = .85, direction = -1, option = 'viridis')(4 + 1)[c(1, 2, 4, 5)]
)

parConv = lapply(c('theta', 'intercept_mu', 'beta_mu', 'sdz0_mu', 'cv', 'sigma'), 
  function(p) Rhat(bestModel, p)) %>% 
  unlist()

print(parConv)
mean(parConv < 1.1, na.rm=TRUE)

metric(bestModel, 'relativeEntropy')

stopifnot(bestIdx <= length(allModels))
```




## Group trajectory plots
### Facetted, mean & sigma, log scale
Group trajectories, log only
```{r}
ggplot(dtTraj, aes(x = Date, group = Class, color = Class,
  y = exp(LogNormNewConfirmed), 
  ymin = exp(LogNormNewConfirmed - Sigma), 
  ymax = exp(LogNormNewConfirmed + Sigma))) +
  scale_x_date(
    breaks = unique(dtTraj$Date)[seq(1, uniqueN(dtTraj$Date), by = 6)],
    minor_breaks = unique(dtTraj$Date)[seq_along(unique(dtTraj$Date)) %% 2 != 0],
    labels = date_format('%b-%d')) +
  scale_y_log10(
    breaks = c(.1, 1, 4, 10, 40, 100, 400), 
    minor_breaks = c(1, 4) * 10 ^ rep(-6:6, each = 2))+
    #sec.axis = sec_axis(~ log(.), breaks = seq(-2, 6, by= 2), name = 'log')) +
  coord_cartesian(ylim = exp(c(-1, 6))) +
  scale_color_manual(name = 'Class', values = colors, na.translate = FALSE) +
  geom_ribbon(fill = NA, linetype = 2) +
  geom_line() +
  geom_point(size=.8) +
  guides(color = FALSE, shape = FALSE) +
  labs(y = 'Weekly new confirmed\ncases / 100,000 inhabitants', title = NULL) +
  theme(axis.text.x=element_text(angle=40, hjust = 1, vjust = 1)) +
  facet_wrap(~ Class)
ggsave(filename=file.path(MVFIG_DIR, 'mv-logtrends_sd.pdf'), width=8.57, height=7, units='cm')
```

### Mean, log scale
```{r}
ggplot(dtTraj, aes(x = Date, y = exp(LogNormNewConfirmed), 
  group = Class, 
  shape = Class, 
  color = Class)) +
  scale_x_date(
    breaks = unique(dtTraj$Date)[seq(1, uniqueN(dtTraj$Date), by = 2)],
    minor_breaks = unique(dtTraj$Date),
    labels = date_format('%b-%d')) +
  scale_y_log10(
    breaks = c(.1, .2, .5, 1, 2, 5, 10, 20, 50, 100, 200, 500), 
    minor_breaks = 1:9 * 10^rep(-6:6, each = 9),
    sec.axis = sec_axis(~ log(.), breaks = -6:6, name = 'log')) +
  scale_color_manual(name = 'Class', values = colors, na.translate = FALSE) +
  geom_line() +
  geom_point() +
  guides(color = guide_legend(override.aes = list(linetype = 0))) +
  labs(y = 'Weekly new confirmed\ncases / 100,000 inhabitants', title = NULL) +
  theme(legend.position = 'top', axis.text.x=element_text(angle=40, hjust = 1, vjust = 1))
ggsave(filename=file.path(MVFIG_DIR, 'mv-logtrends.pdf'), width=8, height=5, units='cm')
```

### Mean, original scale
```{r}
ggplot(dtTraj, aes(x = Date, 
  y = exp(LogNormNewConfirmed), 
  # ymin = exp(LogNormNewConfirmed - Sigma),
  # ymax = exp(LogNormNewConfirmed + Sigma),
  group = Class, 
  shape = Class, 
  color = Class)) +
  scale_x_date(
    breaks = unique(dtTraj$Date)[seq(1, uniqueN(dtTraj$Date), by = 2)],
    minor_breaks = unique(dtTraj$Date),
    labels = date_format('%b-%d')) +
  scale_color_manual(name = 'Class', values = colors, na.translate = FALSE) +
  # geom_ribbon(fill = NA, size = .1) +
  geom_line() +
  geom_point() +
  guides(color = guide_legend(override.aes = list(linetype = 0))) +
  labs(y = 'Weekly new confirmed\ncases / 100,000 inhabitants', title = NULL) +
  theme(legend.position = 'top', axis.text.x=element_text(angle=40, hjust = 1, vjust = 1))
ggsave(filename=file.path(MVFIG_DIR, 'mv-trends.pdf'), width=8.57, height=5, units='cm')
```

### Facetted mean and sigma, original scale
```{r}
ggplot(dtTraj, aes(x = Date, 
  y = exp(LogNormNewConfirmed), 
  ymin = exp(LogNormNewConfirmed - Sigma),
  ymax = exp(LogNormNewConfirmed + Sigma),
  group = Class, 
  shape = Class, 
  fill = Class,
  color = Class)) +
  scale_x_date(
    breaks = unique(dtTraj$Date)[seq(1, uniqueN(dtTraj$Date), by = 2)],
    minor_breaks = unique(dtTraj$Date),
    labels = date_format('%b-%d')) +
  scale_color_manual(name = 'Class', values = colors, na.translate = FALSE) +
  scale_fill_manual(name = 'Class', values = colors, na.translate = FALSE) +
  geom_ribbon(alpha = .1) +
  geom_line(size = 1) +
  geom_point() +
  guides(color = guide_legend(override.aes = list(linetype = 0))) +
  labs(y = 'Weekly new confirmed\ncases / 100,000 inhabitants', title = NULL) +
  theme(legend.position = 'top', axis.text.x=element_text(angle=40, hjust = 1, vjust = 1)) +
  facet_wrap(~Class)
```

Sigma group trajectory plot
```{r}
ggplot(dtTraj, aes(x = Date, y = Sigma, group = Class, shape = Class, color = Class)) +
  scale_x_date(
    breaks = unique(dtTraj$Date)[seq(1, uniqueN(dtTraj$Date), by = 2)],
    minor_breaks = unique(dtTraj$Date),
    labels = date_format('%b-%d')) +
  scale_y_continuous(breaks = pretty_breaks()) +
  scale_color_manual(name = 'Class', values = colors, na.translate = FALSE) +
  geom_line() +
  geom_point() +
  expand_limits(y = 0) +
  guides(color = guide_legend(override.aes = list(linetype = 0))) +
  labs(y = 'log(weekly new confirmed\ncases / 100,000 inhabitants)', title = NULL) +
  theme(legend.position = 'top', axis.text.x=element_text(angle=40, hjust = 1, vjust = 1))
ggsave(filename=file.path(MVFIG_DIR, 'mv-trends_sigma.pdf'), width=8, height=5, units='cm')
```

## Parameter table
```{r}
parMeans = coef(bestModel)
parLo = coef(bestModel, fun = function(...) hdi(..., credMass = .8)[1,]) %>%
  set_names(names(parMeans))
parHi = coef(bestModel, fun = function(...) hdi(..., credMass = .8)[2,]) %>%
  set_names(names(parMeans))

dtpar = data.table(Param = names(parMeans), Est = parMeans, Low = parLo, Up = parHi)

dtpartxt = copy(dtpar) %>%
  .[, Est := sigfig(Est)] %>%
  .[, Low := sigfig(Low)] %>%
  .[, Up := sigfig(Up)] %>% 
  .[]
write.csv(dtpartxt, file = file.path(TABLES_DIR, 'mv-case_params.csv'))

dtpartxt
```


## Classification map
```{r}
mapdata = model.data(bestModel) %>% 
  copy() %>%
  .[, fips := FIPS] %>%
  .[, Class := factor(
    trajectoryAssignments(bestModel)[latrend:::make.idRowIndices(bestModel)],
    levels = clusterNames(bestModel)[clusOrder],
    labels = levels(dtTraj$Class))]

plot_usmap(data = unique(mapdata[, .(fips, Class)]), 
    values = 'Class', 
    region = 'counties', 
    size = .03) +
  scale_fill_manual(name = 'Class', values = colors, na.translate = FALSE) +
  theme(
    # panel.background = element_rect(fill = 'red'),
    plot.margin = unit(c(-10,-3,-3,-3), 'mm'),
    legend.position = c(.03, -.1),
    legend.direction='horizontal'
    )

ggsave(filename=file.path(MVFIG_DIR, 'mv-map.pdf'), width=8.57, height=6.8, units='cm')
```

## Trace plots
```{r warning=FALSE, message=FALSE}
traceplot(bestModel, 
  par = intersect(names(bestModel), 
    c('theta', 'intercept_mu', 'beta_mu', 'sigma', 'sdz0_mu', 'sdz_mu', 'cv'))) +
  scale_color_grey(guide=FALSE) +
  labs(x = 'Iteration', y = 'Posterior value', title = NULL)
# ggsave(filename=file.path(MVFIG_DIR, 'mv-trace.pdf'), width=13, height=10, units='cm')
```

## Comparison to non-parametric model
```{r}
# npmod = lcModelWeightedPartition(data,
#   response = 'LogNormNewConfirmed',
#   weights = postprob(bestModel))

npmod = lcModelPartition(data,
  response = 'LogNormNewConfirmed',
  center = function(x) quantile(x, .5),
  trajectoryAssignments = trajectoryAssignments(bestModel))
```

Compare cluster trajectories visually.
```{r}
plotClusterTrajectories(npmod) +
  expand_limits(y = c(-1, 6))

plotClusterTrajectories(bestModel) +
  expand_limits(y = c(-1, 6))
```

Data plot comparison
```{r}
plot(npmod, trajectories = list(size = .1, alpha=.1), facet = TRUE)
```

```{r}
plot(bestModel, trajectories = list(size = .1, alpha=.1), facet = TRUE)
```

### Distribution plot
mean-SD
```{r}
data[, .(Mean = mean(LogNormNewConfirmed), 
  Low = mean(LogNormNewConfirmed) - sd(LogNormNewConfirmed), 
  High = mean(LogNormNewConfirmed) + sd(LogNormNewConfirmed)), 
  keyby = .(Time, Cluster)] %>%
  ggplot(aes(x = Time, y = Mean, ymin = Low, ymax = High)) +
  geom_ribbon(alpha=.5) +
  geom_line() +
  facet_wrap(~ Cluster)
```

```{r}
data[, .(Mean = mean(LogNormNewConfirmed), SD = sd(LogNormNewConfirmed)), keyby=.(Cluster)]
```


Trajectory-specific SD
```{r}
data[, .(SD = sd(diff(LogNormNewConfirmed / sqrt(2)))), keyby=.(Cluster, FIPS)] %>%
  .[, as.list(summary(SD)), keyby=Cluster] %>%
  merge(dtTraj[, .(ClusEst = mean(Sigma)), by=Cluster], by = 'Cluster')
```


Quantiles
```{r}
data[, as.list(quantile(LogNormNewConfirmed, probs = c(.1, .5, .9))) %>% set_names(c('Low', 'Y', 'High')), keyby = .(Time, Cluster)] %>%
  ggplot(aes(x = Time, y = Y, ymin = Low, ymax = High)) +
  geom_ribbon(alpha=.5) +
  geom_line() +
  facet_wrap(~ Cluster)
```

## Post-hoc analysis
Load data
```{r}
maskData = read.csv(params$MaskData) %>%
  setDT() %>%
  setnames('COUNTYFP', 'fips') %>%
  .[, MaskUseProb := ALWAYS + .8 * FREQUENTLY + .5 * SOMETIMES + .2 * RARELY] %>% 
  .[, NoMaskUseProb := 1 - MaskUseProb] %>% 
  setnames('NEVER', 'MaskUse.Never') %>%
  setnames('RARELY', 'MaskUse.Rarely') %>%
  setnames('SOMETIMES', 'MaskUse.Sometimes') %>%
  setnames('FREQUENTLY', 'MaskUse.Frequently') %>%
  setnames('ALWAYS', 'MaskUse.Always') %>%
  .[]

prevData = read.csv(params$PrevalenceData, sep = ';') %>%
  setDT() %>%
  setnames('FIPS', 'fips') %>%
  .[]

densData = read.csv(params$DensityData) %>% 
  setDT() %>%
  .[fips > 0] %>%
  setnames('POP060210', 'PopSqM') %>%
  .[, PopSqKm := PopSqM / 2.58998811] %>%
  setnames('AGE775212', 'SeniorPrevalence') %>%
  setnames('POP010210', 'Population2010') %>%
  setnames('SEX255212', 'FemalePrevalence') %>%
  .[]

allRawCovidData = load_csse_covid19_data() %>%
  .[Population > 0] %>%
  .[Lat != 0] %>%
  .[County != ''] %>%
  .[is.finite(FIPS)] %>%
  .[, fips := FIPS] %>%
  .[]

deathData = allRawCovidData[Date %between% c(min(data$FirstDate) + 14, max(data$LastDate) + 14), .(TotalDeaths = max(Deaths) - min(Deaths)), keyby = .(fips)]
infectData = allRawCovidData[Date %between% c(min(data$FirstDate), max(data$LastDate)), .(TotalInfected = max(Confirmed) - min(Confirmed)), keyby = .(fips)]

countyData = merge(maskData, prevData, by = 'fips') %>%
  merge(densData, by = 'fips') %>%
  merge(deathData, by = 'fips') %>%
  merge(infectData, by = 'fips') %>%
  .[, DeathProp := TotalDeaths / TotalInfected] %>%
  merge(unique(data, by = 'fips'), by = 'fips') %>%
  .[, NormTotalDeaths := TotalDeaths / Population * 1e5] %>%
  .[, NormTotalInfected := TotalInfected / Population * 1e5] %>%
  .[Population > 0 & PopSqKm > 0]
```

```{r}
mod_clus = multinom(Class ~ log(Population) + log(PopSqKm) + Obesity_prevalence + CKD_prevalence + SeniorPrevalence, data = countyData, Hess = TRUE)
Anova(mod_clus)

emmeans(mod_clus, ~ Class)
emmeans(mod_clus, ~ Population | Class)
emmeans(mod_clus, ~ CKD_prevalence | Class)

summary(mod_clus)
```


Compare population size
```{r}
countyData[, .(Mean = mean(Population), Median = median(Population)), keyby = Class]

# median
mod_lpop = lm(log(Population) ~ Class, data = countyData)
anova(mod_lpop)
emmeans(mod_lpop, pairwise ~ Class, type = 'response')
```

Compare population density
```{r}
countyData[, .(Mean = mean(PopSqKm), Median = median(PopSqKm)), keyby = Class]

# median
mod_ldens = lm(log(PopSqKm) ~ Class, data = countyData[PopSqKm > 0])
anova(mod_ldens)
emmeans(mod_ldens, pairwise ~ Class, type = 'response')
```

Compare seniors
```{r}
mod_seniors = lm(SeniorPrevalence ~ Class, data = countyData)
anova(mod_seniors)
emmeans(mod_seniors, pairwise ~ Class, type = 'response')
```

Compare any condition
```{r}
mod_any = lm(anycondition_prevalence ~ Class + log(Population) + log(PopSqKm), data = countyData)
af = anova(mod_any)
afss <- af$"Sum Sq"
print(cbind(af,PctExp=afss/sum(afss)*100))

emmeans(mod_any, pairwise ~ Class)
```

Compare HF
```{r}
mod_dia = lm(Heart.disease_prevalence ~ Class + diabetes_prevalence + Obesity_prevalence + CKD_prevalence + log(Population) + log(PopSqKm) + COPD_prevalence, data = countyData)
af = anova(mod_dia)
afss <- af$"Sum Sq"
print(cbind(af,PctExp=afss/sum(afss)*100))

emmeans(mod_dia, pairwise ~ Class)
```

Compare obesity
```{r}
mod_ob = lm(Obesity_prevalence ~ Class + diabetes_prevalence + CKD_prevalence + Heart.disease_prevalence + log(Population) + log(PopSqKm) + COPD_prevalence, data = countyData)
af = anova(mod_ob)
afss <- af$"Sum Sq"
print(cbind(af,PctExp=afss/sum(afss)*100))

emmeans(mod_ob, pairwise ~ Class)
```

Compare diabetes
```{r}
mod_dia = lm(diabetes_prevalence ~ Class + Obesity_prevalence + CKD_prevalence + Heart.disease_prevalence + log(Population) + log(PopSqKm) + COPD_prevalence, data = countyData)
af = anova(mod_dia)
afss <- af$"Sum Sq"
print(cbind(af,PctExp=afss/sum(afss)*100))

emmeans(mod_dia, pairwise ~ Class)
```

Mask usage probability
```{r}
mod_mask = lm(MaskUseProb ~ Class + log(Population) + log(PopSqKm), data = countyData)
af = anova(mod_mask)
afss <- af$"Sum Sq"
print(cbind(af,PctExp=afss/sum(afss)*100))

emmeans(mod_mask, pairwise ~ Class)
```

Infected normalized by population
```{r}
countyData[, .(NormDeaths = mean(NormTotalDeaths), NormInfects = mean(NormTotalInfected)), keyby=Class]

mod_norminf = lm(NormTotalInfected ~ SeniorPrevalence + CKD_prevalence + Heart.disease_prevalence + diabetes_prevalence + Obesity_prevalence + COPD_prevalence + Class + log(Population) + log(PopSqKm), data = countyData)
af = anova(mod_norminf)
afss <- af$"Sum Sq"
print(cbind(af,PctExp=afss/sum(afss)*100))

emmeans(mod_norminf, pairwise ~ Class)
```

Deaths normalized by population
```{r}
countyData[, .(NormDeaths = mean(NormTotalDeaths), NormInfects = mean(NormTotalInfected)), keyby=Class]

mod_normdeaths = lm(log(NormTotalDeaths + .001) ~ NormTotalInfected + SeniorPrevalence + CKD_prevalence + Heart.disease_prevalence + Obesity_prevalence + diabetes_prevalence + COPD_prevalence + Class + log(Population) + log(PopSqKm), data = countyData)
af = anova(mod_normdeaths)
afss <- af$"Sum Sq"
print(cbind(af,PctExp=afss/sum(afss)*100))

emmeans(mod_normdeaths, pairwise ~ Class, type = 'response')
```

Excess COVID-19 death rate with 14-day lag
Look at total number of new cases within the 15 weeks, and the 14-day lagged cumulative death rate.

Any deaths
```{r}
mod_anydeaths = glm(I(TotalDeaths > 0) ~ Obesity_prevalence + CKD_prevalence + COPD_prevalence + Class + log(Population) + log(PopSqKm), data = countyData[TotalInfected > 0], family = binomial(link = "logit"))
Anova(mod_anydeaths)

coef(mod_anydeaths)
```

Non-zero deaths
```{r}
mod_deaths = lm(log(TotalDeaths / TotalInfected) ~ Obesity_prevalence + CKD_prevalence + COPD_prevalence + Class + log(Population) + log(PopSqKm), data = countyData[TotalInfected > 0 & TotalDeaths > 0])

af = anova(mod_deaths)
afss <- af$"Sum Sq"
print(cbind(af,PctExp=afss/sum(afss)*100))
```


Average death prop
```{r}
countyData[, sum(TotalDeaths) / sum(TotalInfected), keyby=Class]

mod_deaths = lm(log(TotalDeaths / TotalInfected + .001) ~ Obesity_prevalence + CKD_prevalence + COPD_prevalence + Heart.disease_prevalence + diabetes_prevalence + Class + log(Population) + log(PopSqKm), data = countyData[TotalInfected > 0])
af = anova(mod_deaths)
afss <- af$"Sum Sq"
print(cbind(af,PctExp=afss/sum(afss)*100))

emmeans(mod_deaths, pairwise ~ Class, type = 'response')
```

### Spatial correlation modeling
See errorsarlm from the spdep package.

# Session info
```{r}
sessionInfo()
```
